{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b4c50a-1ad6-4723-8b66-cfd43b000e17",
   "metadata": {},
   "source": [
    "# 使用 TorchAcc 加速 OLMo 模型训练\n",
    "\n",
    "TorchAcc是基于Pytorch的分布式训练加速框架。本文将介绍通过简单引入TorchAcc的几行代码来加速OLMo模型训练的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e2de59-973f-4b3f-94df-24e12d7345d1",
   "metadata": {},
   "source": [
    "# 1. 环境准备\n",
    "\n",
    "安装OLMo相关的依赖。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f635eee-04e9-47b2-bb7b-8314d0b1adfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.34.43)\n",
      "Requirement already satisfied: cached-path in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (13.7.0)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.43 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.34.43)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cached-path) (2.31.0)\n",
      "Requirement already satisfied: filelock<3.13,>=3.4 in /usr/local/lib/python3.10/dist-packages (from cached-path) (3.12.4)\n",
      "Requirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from cached-path) (2.14.0)\n",
      "Requirement already satisfied: huggingface-hub<0.20.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from cached-path) (0.19.4)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich) (2.17.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.43->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.43->boto3) (2.0.7)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.23.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path) (2.27.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path) (2.7.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path) (1.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.20.0,>=0.8.1->cached-path) (2023.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.20.0,>=0.8.1->cached-path) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.20.0,>=0.8.1->cached-path) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.20.0,>=0.8.1->cached-path) (23.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.0->cached-path) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.0->cached-path) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.0->cached-path) (2023.11.17)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path) (1.62.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path) (3.20.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path) (4.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.43->boto3) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path) (0.5.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Collecting git+https://github.com/allenai/OLMo\n",
      "  Cloning https://github.com/allenai/OLMo to /tmp/pip-req-build-a1itauad\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/allenai/OLMo /tmp/pip-req-build-a1itauad\n",
      "  Resolved https://github.com/allenai/OLMo to commit 9fd9130d25ac2249c381a6283e6ea8d954aeab23\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! pip install boto3 cached-path omegaconf rich\n",
    "! pip install git+https://github.com/allenai/OLMo --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43fc58f-8339-431f-9709-c309fcdcc9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import itertools\n",
    "import torch\n",
    "import torchacc\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, get_scheduler, default_data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb3389b-7fc4-464b-8de5-cd685913decd",
   "metadata": {},
   "source": [
    "# 2. 准备训练数据\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e43d494-4243-4a69-8974-87cd723535e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(tokenizer, max_seq_length, batch_size):\n",
    "    raw_datasets = datasets.load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split='train')\n",
    "    column_names = list(raw_datasets.features)\n",
    "    text_column_name = 'text' if 'text' in column_names else column_names[0]\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[text_column_name], return_token_type_ids=False)\n",
    "\n",
    "    tokenized_datasets = raw_datasets.map(tokenize_function, batched=True, remove_columns=column_names)\n",
    "    block_size = max_seq_length\n",
    "\n",
    "    def group_texts(examples):\n",
    "        concatenated_examples = {k: list(itertools.chain(*examples[k])) for k in examples.keys()}\n",
    "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "        if total_length >= block_size: total_length = (total_length // block_size) * block_size\n",
    "        result = { k: [ t[i:i + block_size] for i in range(0, total_length, block_size) ] for k, t in concatenated_examples.items() }\n",
    "        result['labels'] = result['input_ids'].copy()\n",
    "        return result\n",
    "\n",
    "    train_dataset = tokenized_datasets.map(group_texts, batched=True)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, collate_fn=default_data_collator)\n",
    "\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70dce63-c1a4-4960-a1e5-e2a6cc1d2192",
   "metadata": {},
   "source": [
    "# 3. 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e6ed4e-8d58-472e-8fcd-82e20633eb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLMoForCausalLM(\n",
      "  (model): Olmo(\n",
      "    (transformer): ModuleDict(\n",
      "      (wte): Embedding(50304, 2048)\n",
      "      (emb_drop): Dropout(p=0.0, inplace=False)\n",
      "      (ln_f): LayerNorm()\n",
      "      (blocks): ModuleList(\n",
      "        (0-15): 16 x OlmoSequentialBlock(\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (act): SwiGLU()\n",
      "          (attn_out): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (ff_out): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "          (rotary_emb): RotaryEmbedding()\n",
      "          (attn_norm): LayerNorm()\n",
      "          (ff_norm): LayerNorm()\n",
      "          (att_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "          (ff_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
      "        )\n",
      "      )\n",
      "      (ff_out): Embedding(50304, 2048)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"allenai/OLMo-1B\", cache_dir=\"./hf_models\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/OLMo-1B\", use_fast=False, trust_remote_code=True)\n",
    "train_loader = get_dataloader(tokenizer, max_seq_length=2048, batch_size=1)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fb5264-7e86-4ff7-8260-824a26d89518",
   "metadata": {},
   "source": [
    "# 4. 使用 TorchAcc 加速模型训练\n",
    "\n",
    "通过TorchAcc加速模型训练一般需要三个步骤：\n",
    "\n",
    "1. 定义`TorchAcc.Config`\n",
    "   \n",
    "   定义`TorchAcc.Config`，并指定加速选项。\n",
    "   \n",
    "2. 调用`torchacc.accelerate`\n",
    "   \n",
    "   调用`torchacc.accelerate`，并传入model和config，完成加速训练的准备。\n",
    "   \n",
    "3. 加速数据加载\n",
    "   \n",
    "   通过`TorchAcc.AsyncLoader`对torch dataset_loader进行封装，加速数据加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b79c942-6d17-4e28-a092-7944fe0f5a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_xla/core/xla_model.py:110: UserWarning: `devkind` argument is deprecated and will be removed in a future release.\n",
      "  warnings.warn(\"`devkind` argument is deprecated and will be removed in a \"\n"
     ]
    }
   ],
   "source": [
    "# 简单定义 TorchAcc 配置\n",
    "config = torchacc.Config()\n",
    "config.compute.bf16 = True # 开启 bf16\n",
    "config.compute.acc_scaled_dot_attn = True # 自动替换Torch ScaledDot 为使用 torchacc flash attn 版本\n",
    "config.dist.fsdp.size = torchacc.dist.world_size() # 开启 FSDP，设置 FSDP 数目\n",
    "config.dist.fsdp.wrap_layer_cls = {\"OlmoSequentialBlock\"} # 传入将OLMo模型的decoder layer进行FSDP封装\n",
    "\n",
    "# 一行代码加速模型\n",
    "model = torchacc.accelerate(model=model, config=config)\n",
    "\n",
    "# 异步加速数据加载\n",
    "train_loader = torchacc.AsyncLoader(train_loader, model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2fbee3-a052-43cd-8237-f061a013ea38",
   "metadata": {},
   "source": [
    "# 5. 定义Optimizer和LR scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018697a1-abb5-46af-b1b6-9db42cd433f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, betas=(0.9, 0.999), eps=1e-8)\n",
    "lr_scheduler = get_scheduler(name='linear', optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200029ec-616d-4bfd-a7e4-7e4e9bb0b769",
   "metadata": {},
   "source": [
    "# 6. 开始训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6242ab1c-cf19-4b51-9caf-27187be28d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:690: UserWarning: aten::reshape: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /workspace/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1708095186.985443    2027 hlo_rematerialization.cc:2946] Can't reduce memory use below 179.31MiB (188023804 bytes) by rematerialization; only reduced to 24.20GiB (25986106296 bytes), down from 25.15GiB (26999801936 bytes) originally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0/1154] loss: 2.66 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1708095196.056070    2027 hlo_rematerialization.cc:2946] Can't reduce memory use below 194.51MiB (203962189 bytes) by rematerialization; only reduced to 23.80GiB (25559335832 bytes), down from 24.74GiB (26560471082 bytes) originally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 10/1154] loss: 3.25 .\n",
      "[Iteration 20/1154] loss: 3.22 .\n",
      "[Iteration 30/1154] loss: 3.69 .\n",
      "[Iteration 40/1154] loss: 3.17 .\n",
      "[Iteration 50/1154] loss: 3.23 .\n",
      "[Iteration 60/1154] loss: 3.27 .\n",
      "[Iteration 70/1154] loss: 3.28 .\n",
      "[Iteration 80/1154] loss: 3.44 .\n",
      "[Iteration 90/1154] loss: 3.33 .\n",
      "[Iteration 100/1154] loss: 3.32 .\n",
      "[Iteration 110/1154] loss: 3.47 .\n",
      "[Iteration 120/1154] loss: 3.54 .\n",
      "[Iteration 130/1154] loss: 3.51 .\n",
      "[Iteration 140/1154] loss: 3.17 .\n",
      "[Iteration 150/1154] loss: 3.43 .\n",
      "[Iteration 160/1154] loss: 3.42 .\n",
      "[Iteration 170/1154] loss: 3.46 .\n",
      "[Iteration 180/1154] loss: 3.45 .\n",
      "[Iteration 190/1154] loss: 3.16 .\n",
      "[Iteration 200/1154] loss: 3.50 .\n",
      "[Iteration 210/1154] loss: 3.30 .\n",
      "[Iteration 220/1154] loss: 3.56 .\n",
      "[Iteration 230/1154] loss: 3.06 .\n",
      "[Iteration 240/1154] loss: 3.50 .\n",
      "[Iteration 250/1154] loss: 3.42 .\n",
      "[Iteration 260/1154] loss: 3.39 .\n",
      "[Iteration 270/1154] loss: 3.51 .\n",
      "[Iteration 280/1154] loss: 3.80 .\n",
      "[Iteration 290/1154] loss: 3.90 .\n",
      "[Iteration 300/1154] loss: 3.37 .\n",
      "[Iteration 310/1154] loss: 3.40 .\n",
      "[Iteration 320/1154] loss: 3.59 .\n",
      "[Iteration 330/1154] loss: 3.21 .\n",
      "[Iteration 340/1154] loss: 3.66 .\n",
      "[Iteration 350/1154] loss: 3.61 .\n",
      "[Iteration 360/1154] loss: 3.59 .\n",
      "[Iteration 370/1154] loss: 3.18 .\n",
      "[Iteration 380/1154] loss: 3.23 .\n",
      "[Iteration 390/1154] loss: 3.22 .\n",
      "[Iteration 400/1154] loss: 3.35 .\n",
      "[Iteration 410/1154] loss: 3.26 .\n",
      "[Iteration 420/1154] loss: 3.14 .\n",
      "[Iteration 430/1154] loss: 3.06 .\n",
      "[Iteration 440/1154] loss: 3.17 .\n",
      "[Iteration 450/1154] loss: 3.63 .\n",
      "[Iteration 460/1154] loss: 3.43 .\n",
      "[Iteration 470/1154] loss: 3.08 .\n",
      "[Iteration 480/1154] loss: 3.53 .\n",
      "[Iteration 490/1154] loss: 3.49 .\n",
      "[Iteration 500/1154] loss: 3.22 .\n",
      "[Iteration 510/1154] loss: 3.05 .\n",
      "[Iteration 520/1154] loss: 3.10 .\n",
      "[Iteration 530/1154] loss: 2.56 .\n",
      "[Iteration 540/1154] loss: 3.29 .\n",
      "[Iteration 550/1154] loss: 3.04 .\n",
      "[Iteration 560/1154] loss: 3.70 .\n",
      "[Iteration 570/1154] loss: 3.51 .\n",
      "[Iteration 580/1154] loss: 2.94 .\n",
      "[Iteration 590/1154] loss: 2.97 .\n",
      "[Iteration 600/1154] loss: 3.30 .\n",
      "[Iteration 610/1154] loss: 3.31 .\n",
      "[Iteration 620/1154] loss: 3.34 .\n",
      "[Iteration 630/1154] loss: 3.49 .\n",
      "[Iteration 640/1154] loss: 3.68 .\n",
      "[Iteration 650/1154] loss: 3.05 .\n",
      "[Iteration 660/1154] loss: 3.29 .\n",
      "[Iteration 670/1154] loss: 3.16 .\n",
      "[Iteration 680/1154] loss: 2.94 .\n",
      "[Iteration 690/1154] loss: 3.07 .\n",
      "[Iteration 700/1154] loss: 3.28 .\n",
      "[Iteration 710/1154] loss: 3.12 .\n",
      "[Iteration 720/1154] loss: 3.36 .\n",
      "[Iteration 730/1154] loss: 3.50 .\n",
      "[Iteration 740/1154] loss: 3.16 .\n",
      "[Iteration 750/1154] loss: 2.49 .\n",
      "[Iteration 760/1154] loss: 2.97 .\n",
      "[Iteration 770/1154] loss: 2.93 .\n",
      "[Iteration 780/1154] loss: 3.07 .\n",
      "[Iteration 790/1154] loss: 2.85 .\n",
      "[Iteration 800/1154] loss: 3.08 .\n",
      "[Iteration 810/1154] loss: 3.57 .\n",
      "[Iteration 820/1154] loss: 2.50 .\n",
      "[Iteration 830/1154] loss: 3.41 .\n",
      "[Iteration 840/1154] loss: 2.90 .\n",
      "[Iteration 850/1154] loss: 2.97 .\n",
      "[Iteration 860/1154] loss: 3.39 .\n",
      "[Iteration 870/1154] loss: 2.98 .\n",
      "[Iteration 880/1154] loss: 2.86 .\n",
      "[Iteration 890/1154] loss: 2.90 .\n",
      "[Iteration 900/1154] loss: 3.20 .\n",
      "[Iteration 910/1154] loss: 3.42 .\n",
      "[Iteration 920/1154] loss: 2.91 .\n",
      "[Iteration 930/1154] loss: 3.25 .\n",
      "[Iteration 940/1154] loss: 2.76 .\n",
      "[Iteration 950/1154] loss: 3.22 .\n",
      "[Iteration 960/1154] loss: 3.53 .\n",
      "[Iteration 970/1154] loss: 3.21 .\n",
      "[Iteration 980/1154] loss: 3.14 .\n",
      "[Iteration 990/1154] loss: 2.89 .\n",
      "[Iteration 1000/1154] loss: 3.00 .\n",
      "[Iteration 1010/1154] loss: 2.71 .\n",
      "[Iteration 1020/1154] loss: 2.38 .\n",
      "[Iteration 1030/1154] loss: 2.78 .\n",
      "[Iteration 1040/1154] loss: 3.07 .\n",
      "[Iteration 1050/1154] loss: 2.77 .\n",
      "[Iteration 1060/1154] loss: 3.15 .\n",
      "[Iteration 1070/1154] loss: 2.23 .\n",
      "[Iteration 1080/1154] loss: 2.73 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1708095716.881173    2027 hlo_rematerialization.cc:2946] Can't reduce memory use below 194.51MiB (203962193 bytes) by rematerialization; only reduced to 23.80GiB (25559335832 bytes), down from 24.74GiB (26560471082 bytes) originally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1090/1154] loss: 2.59 .\n",
      "[Iteration 1100/1154] loss: 3.27 .\n",
      "[Iteration 1110/1154] loss: 3.09 .\n",
      "[Iteration 1120/1154] loss: 3.08 .\n",
      "[Iteration 1130/1154] loss: 3.29 .\n",
      "[Iteration 1140/1154] loss: 3.12 .\n",
      "[Iteration 1150/1154] loss: 2.92 .\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for step, inputs in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "        loss = model(**inputs)['loss']\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        torchacc.sync()\n",
    "        print(f'[Iteration {step}/{len(train_loader)}] loss: {loss:.2f} .')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731baf46-e4bb-4def-88bb-053bfc24bf2d",
   "metadata": {},
   "source": [
    "# 7. 分布式训练\n",
    "\n",
    "由于jupyter内很难运行多卡分布式程序，如需运行分布式训练，建议在GPU开发机或PAI-DLC上运行以下脚本（其中`train_olmo.py`可通过jupyter Notebook将当前文件导出为Python文件，导出步骤为：`File-> Save and Export Notebook as -> Executable Script` ）。\n",
    "\n",
    "```shell\n",
    "pip install boto3 cached-path omegaconf rich\n",
    "pip install git+https://github.com/allenai/OLMo --no-deps\n",
    "\n",
    "torchrun --nproc_per_node=4 train_olmo.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
